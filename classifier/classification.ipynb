{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from functools import reduce\n",
    "from os import listdir, sep\n",
    "from os.path import isfile\n",
    "from random import shuffle\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Entwork, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(1, 6, (3, 20))\n",
    "        self.cv2 = nn.Conv2d(6, 16, (3, 20))\n",
    "        self.fc1 = nn.Linear(4992, 500)\n",
    "        self.fc2 = nn.Linear(500, 50)\n",
    "        self.fc3 = nn.Linear(50, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.cv1(x)), (3, 3))\n",
    "        x = F.max_pool2d(F.relu(self.cv2(x)), (3, 3))\n",
    "        x = x.view(-1, reduce(lambda z, y: z * y, x.size()[1:], 1))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = re.compile(r\"\\d\")\n",
    "splitter = re.compile(r\"\\s+\")\n",
    "punctuation = re.compile(r\"((?<!\\d)[.,](?!\\d)|[\\n?!:;\\()/\\\\\\-_=*])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(p):\n",
    "    with open(p) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        for line in reader:\n",
    "            yield line[0], splitter.split(punctuation.sub(\" \", digit.sub(\"#\", line[1].lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 3543 revies from Kaapelit.csv\n",
      "read 1927 revies from Koti-ja-valaistus.csv\n",
      "read 1976 revies from Kodinkoneet.csv\n",
      "read 901 revies from Kellot.csv\n",
      "read 7795 revies from Puhelimet.csv\n",
      "read 4709 revies from Kamerat.csv\n",
      "read 1091 revies from Lelut.csv\n",
      "read 5019 revies from Audio-ja-hifi.csv\n",
      "read 3251 revies from Laukut-ja-matkailu.csv\n",
      "read 1308 revies from Grillaus-ja-kokkaus.csv\n",
      "read 3428 revies from Tarvike-ja-toimisto.csv\n",
      "read 3706 revies from Komponentit.csv\n",
      "read 1768 revies from Musiikki.csv\n",
      "read 2177 revies from Verkko.csv\n",
      "read 451 revies from Lemmikit.csv\n",
      "read 2529 revies from TV-ja-video.csv\n",
      "read 3281 revies from Pelit-ja-viihde.csv\n",
      "read 873 revies from Ohjelmistot.csv\n",
      "read 5931 revies from Tietokoneet.csv\n",
      "read 4186 revies from Pienkoneet.csv\n",
      "read 5517 revies from Oheislaitteet.csv\n",
      "read 1150 revies from Vauvat-ja-perhe.csv\n",
      "read 2306 revies from Urheilu.csv\n",
      "read 1482 revies from Ruoka-ja-juoma.csv\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "csv_path = \"/home/local/saska/Documents/rev\"\n",
    "for p in listdir(csv_path):\n",
    "    ap = list(read_sentences(\"{}{}{}\".format(csv_path, sep, p)))\n",
    "    print(\"read {} revies from {}\".format(len(ap), p))\n",
    "    ls.extend(ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store to file for fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/local/saska/Documents/fastt/lines\", 'w') as out_file:\n",
    "    out_file.write(\"\\n\".join([\" \".join(line[1]) for line in ls]))\n",
    "\n",
    "s = set()\n",
    "for line in ls:\n",
    "    for w in line[1]:\n",
    "        s.add(w)\n",
    "\n",
    "with open(\"/home/local/saska/Documents/fastt/queries\", 'w') as out_file:\n",
    "    out_file.write(\"\\n\".join(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "fastText-0.1.0/fasttext skipgram -input lines -output model -dim 200\n",
    "fastText-0.1.0/fasttext print-word-vectors model.bin < queries > vecs.txt\n",
    "```\n",
    "# Tensor length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.00718298840765 % of reviews are of lenght 232 or shorter\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "for review in ls:\n",
    "    if len(review[1]) in d:\n",
    "        d[len(review[1])] += 1\n",
    "    else:\n",
    "        d[len(review[1])] = 1\n",
    "        \n",
    "l = 0\n",
    "count = 0\n",
    "while count < 0.99 * len(ls):\n",
    "    if l in d:\n",
    "        count += d[l]\n",
    "    l += 1\n",
    "    \n",
    "print(\"{} % of reviews are of lenght {} or shorter\".format(100 * count/len(ls), l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sentence tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175362\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "fuu = False\n",
    "with open(\"/home/local/saska/Documents/fastt/vecs.txt\") as in_file:\n",
    "    rd = csv.reader(in_file, delimiter=\" \", quotechar=\"¤\")\n",
    "    for line in rd:      \n",
    "        if len(line) > 2:\n",
    "            d[line[0]] = np.asarray(line[1:-1], dtype=np.float32)\n",
    "\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(d[\"hyvä\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_tensor(sentence, embeddings, block_length):\n",
    "    return torch.stack([torch.stack([get_embedding(i, sentence, embeddings) for i in range(block_length)])])\n",
    "\n",
    "def get_embedding(idx, sentence, embeddings):\n",
    "    return (torch.from_numpy(embeddings[sentence[idx]])\n",
    "            if len(sentence) > idx and sentence[idx] in embeddings\n",
    "            else torch.zeros(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_len = 230\n",
    "tensor_refs = []\n",
    "'''for i, review in enumerate(ls):\n",
    "    nam = \"tensors/{}.pt\".format(i)\n",
    "    tensor_refs.append((int(review[0]) - 1, nam))\n",
    "    torch.save(get_sentence_tensor(review[1], d, block_len), nam)'''\n",
    "with open(\"meta.txt\") as in_file:\n",
    "    csv_reader = csv.reader(in_file)\n",
    "    for i, l, f in csv_reader:\n",
    "        tensor_refs.append((int(i), int(l), f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceLoader(Dataset):\n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ten = torch.load(self.metadata[idx][2])\n",
    "        return {'lable': self.metadata[idx][1], 'ten': ten}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(tensor_refs)\n",
    "testDataLoader = DataLoader(SentenceLoader(tensor_refs[:300]), shuffle=False, batch_size=100)\n",
    "trainDataLoader = DataLoader(SentenceLoader(tensor_refs[300:]), shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "### Clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(d)\n",
    "del(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "epoch 0 loss: 1094.6773493289948\n",
      "epoch 1 loss: 989.3744008541107\n",
      "epoch 2 loss: 984.8980747461319\n",
      "epoch 3 loss: 984.2620143890381\n",
      "epoch 4 loss: 983.8540791273117\n",
      "epoch 5 loss: 983.6242444515228\n",
      "epoch 6 loss: 983.7645877599716\n",
      "epoch 7 loss: 983.2722520828247\n",
      "epoch 8 loss: 983.5745230913162\n",
      "epoch 9 loss: 983.0713748931885\n",
      "Evaluating model accuracy...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Variable data has to be a tensor, but got str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bdaab3446447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Variable data has to be a tensor, but got str"
     ]
    }
   ],
   "source": [
    "ent = Entwork()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ent.parameters(), lr=0.001, momentum=0.9)\n",
    "print(\"Training...\")\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainDataLoader):\n",
    "        labels, inputs = data[\"lable\"], data[\"ten\"]\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outs = ent(inputs)\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "    print(\"epoch {} loss: {}\".format(epoch, running_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model accuracy...\n",
      "Actual: 4, predicted: 3\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 1, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 1, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 1, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 3\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 1, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 1, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 1, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 0, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 1, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 2, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 4, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Actual: 3, predicted: 4\n",
      "Accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model accuracy...\")\n",
    "c = 0\n",
    "for i, data in enumerate(testDataLoader):\n",
    "    labels, inputs = data[\"lable\"], data[\"ten\"]\n",
    "    outs = ent(Variable(inputs))\n",
    "    _, preds = torch.max(outs.data, 1)\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == preds[i]:\n",
    "            c += 1\n",
    "        print(\"Actual: {}, predicted: {}\".format(labels[i], preds[i]))\n",
    "print(\"Accuracy: {}\".format(c / 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
